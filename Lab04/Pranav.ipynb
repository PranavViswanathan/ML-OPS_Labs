{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aa01bce-ce09-4234-a4a9-fb7c1ace1982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.22.3-py3-none-macosx_12_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click>=8.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (24.2)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: pydantic<3 in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (2.18.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /opt/anaconda3/lib/python3.12/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3->wandb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3->wandb) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (4.0.0)\n",
      "Downloading wandb-0.22.3-py3-none-macosx_12_0_arm64.whl (18.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wandb\n",
      "Successfully installed wandb-0.22.3\n"
     ]
    }
   ],
   "source": [
    "! pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2123a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e6194",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6608e142-e943-4c82-b3e7-3b958bda4989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.1.1-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.12.0)\n",
      "Downloading xgboost-3.1.1-py3-none-macosx_12_0_arm64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-3.1.1\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c79021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">xgboost</strong> at: <a href='https://wandb.ai/pranav-viswanathan-northeastern-university/Lab1-visualize-models/runs/md34fa9g' target=\"_blank\">https://wandb.ai/pranav-viswanathan-northeastern-university/Lab1-visualize-models/runs/md34fa9g</a><br> View project at: <a href='https://wandb.ai/pranav-viswanathan-northeastern-university/Lab1-visualize-models' target=\"_blank\">https://wandb.ai/pranav-viswanathan-northeastern-university/Lab1-visualize-models</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251031_114655-md34fa9g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/pranavviswanathan/Northeastern/Education/Fall2025/ML-OPS/Labs/ML-OPS_Labs/Lab4/wandb/run-20251031_114830-rmat4k5d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo/runs/rmat4k5d' target=\"_blank\">cnn-cifar10</a></strong> to <a href='https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo' target=\"_blank\">https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo/runs/rmat4k5d' target=\"_blank\">https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo/runs/rmat4k5d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 170M/170M [01:10<00:00, 2.43MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/10:\n",
      "  Train Loss: 1.4452, Train Acc: 47.09%\n",
      "  Val Loss: 1.0802, Val Acc: 61.68%\n",
      "Epoch 2/10:\n",
      "  Train Loss: 1.0317, Train Acc: 63.22%\n",
      "  Val Loss: 0.9318, Val Acc: 67.12%\n",
      "Epoch 3/10:\n",
      "  Train Loss: 0.8375, Train Acc: 70.41%\n",
      "  Val Loss: 0.7946, Val Acc: 71.90%\n",
      "Epoch 4/10:\n",
      "  Train Loss: 0.7173, Train Acc: 74.88%\n",
      "  Val Loss: 0.7478, Val Acc: 74.19%\n",
      "Epoch 5/10:\n",
      "  Train Loss: 0.6254, Train Acc: 78.03%\n",
      "  Val Loss: 0.7196, Val Acc: 75.05%\n",
      "Epoch 6/10:\n",
      "  Train Loss: 0.5521, Train Acc: 80.38%\n",
      "  Val Loss: 0.7475, Val Acc: 74.91%\n",
      "Epoch 7/10:\n",
      "  Train Loss: 0.4833, Train Acc: 82.76%\n",
      "  Val Loss: 0.6813, Val Acc: 77.75%\n",
      "Epoch 8/10:\n",
      "  Train Loss: 0.4195, Train Acc: 85.19%\n",
      "  Val Loss: 0.7054, Val Acc: 77.41%\n",
      "Epoch 9/10:\n",
      "  Train Loss: 0.3771, Train Acc: 86.41%\n",
      "  Val Loss: 0.7372, Val Acc: 76.88%\n",
      "Epoch 10/10:\n",
      "  Train Loss: 0.3297, Train Acc: 88.14%\n",
      "  Val Loss: 0.7337, Val Acc: 76.74%\n",
      "\n",
      "Final Validation Accuracy: 76.74%\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>▁▃▄▄▄▇▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>batch_loss</td><td>█▆▆▅▃▄▄▃▃▅▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▂▂▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_accuracy</td><td>88.28236</td></tr><tr><td>batch_loss</td><td>0.29642</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>final_train_accuracy</td><td>88.142</td></tr><tr><td>final_val_accuracy</td><td>76.74</td></tr><tr><td>train_accuracy</td><td>88.142</td></tr><tr><td>train_loss</td><td>0.32973</td></tr><tr><td>val_accuracy</td><td>76.74</td></tr><tr><td>val_loss</td><td>0.73372</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cnn-cifar10</strong> at: <a href='https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo/runs/rmat4k5d' target=\"_blank\">https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo/runs/rmat4k5d</a><br> View project at: <a href='https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo' target=\"_blank\">https://wandb.ai/pranav-viswanathan-northeastern-university/image-classification-demo</a><br>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251031_114830-rmat4k5d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize wandb\n",
    "run = wandb.init(\n",
    "    project=\"image-classification-demo\",\n",
    "    name=\"cnn-cifar10\",\n",
    "    config={\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 64,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"CIFAR-10\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, \n",
    "                                 download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, \n",
    "                                download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=wandb.config.batch_size, \n",
    "                         shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=wandb.config.batch_size, \n",
    "                        shuffle=False, num_workers=2)\n",
    "\n",
    "# Model setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "# Watch model with wandb\n",
    "wandb.watch(model, criterion, log=\"all\", log_freq=100)\n",
    "\n",
    "# Training loop\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Log batch metrics\n",
    "        if batch_idx % 100 == 0:\n",
    "            wandb.log({\n",
    "                \"batch_loss\": loss.item(),\n",
    "                \"batch_accuracy\": 100. * correct / total\n",
    "            })\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Validation function\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100. * correct / total\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(wandb.config.epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Log epoch metrics\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc\n",
    "    })\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{wandb.config.epochs}:')\n",
    "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "# Save final metrics\n",
    "run.summary[\"final_train_accuracy\"] = train_acc\n",
    "run.summary[\"final_val_accuracy\"] = val_acc\n",
    "\n",
    "# Log model as artifact\n",
    "artifact = wandb.Artifact('cnn-model', type='model')\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "artifact.add_file('model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "print(f'\\nFinal Validation Accuracy: {val_acc:.2f}%')\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7691e-4a10-4483-a058-0337dd305207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
