# Lab2_Airflow

This lab demonstrates using Apache Airflow to run a simple machine learning workflow.

## Overview

In this lab, we used the **Boston Housing dataset** and applied **K-Means clustering** to it. The workflow is orchestrated using Apache Airflow DAGs.

## Code Explanation

- **DAG (`kmeans_dag.py`)**:  
  Defines the workflow for loading data, preprocessing, running K-Means clustering, and saving the results. The DAG contains multiple Python tasks, each responsible for a specific step in the ML pipeline.

- **Tasks**:  
  - **Load Data**: Loads the Boston Housing dataset and converts it to a suitable format for clustering.  
  - **Preprocess Data**: Handles any necessary normalization or preprocessing of the features.  
  - **K-Means Clustering**: Applies the K-Means algorithm to cluster the dataset into groups based on housing features.  
  - **Save Outputs**: Stores the clustering results in the `outputs/` folder.  

- **Outputs and Screenshots**:  
  - The `outputs/` folder contains the numerical results of the clustering.  
  - The `screenshots/` folder contains screenshots of the outputs and workflow execution in Airflow.  

## Folder Structure

- `dags/` – Contains the Airflow DAGs and associated Python scripts.  
- `outputs/` – Contains the results generated by the workflow.  
- `screenshots/` – Contains screenshots of outputs and DAG execution.
